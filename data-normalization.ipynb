{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "***\n",
    "**Name**: $<$Guido Rincon$>$ \n",
    "***\n",
    "\n",
    "Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules to be followed for the assignment are:\n",
    "\n",
    "- Do **NOT** load additional packages beyond what we've shared in the cells below. \n",
    "- Some problems with code may be autograded.  If we provide a function or class API **do not** change it.\n",
    "- Do not change the location of the data or data directory.  Use only relative paths to access the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:22:03.370195Z",
     "start_time": "2020-09-10T01:22:02.356211Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "***\n",
    "\n",
    "There are two functions that need to be completed:\n",
    "\n",
    "#### normalization(fname, attr, normType)\n",
    "\n",
    "- This function takes in the location of the data file, the attribute that has to be normalised (one of the values from 'Open','High','Low','Close','Volume') and the type of normalization to be performed('min_max' or 'z_score')\n",
    "\n",
    "- Based on the normalisation type that is mentioned, you will have to apply the appropriate formula and return a dictionary where key = original value in the dataset, value = normalised value\n",
    "\n",
    "- A sample dataset has been provided to you at this location \"./data/HistoricalQuotes.csv\". Use this dataset to test the functionality you are building.\n",
    "\n",
    "#### correlation (fname1, attr1, fname2, attr2)\n",
    "\n",
    "- This function takes in the location of the first data file, the attribute that has to be used in the first file, the location of the second data file and the attribute that has to be used in the second file.\n",
    "\n",
    "- This function has to calculate the correlation coefficient between the two attributes mentioned in the two files.\n",
    "\n",
    "- Two Sample datasets have been provided to you in \"./data/test1.csv\" and \"./data/test2.csv\" respectively.\n",
    "\n",
    "- The two sample files have the following attributes 'Open','High','Last','Low','Volume'. Use these two sample files to test the functionality you are building.\n",
    "\n",
    "Note:\n",
    "- If the test case fails, one way to debug is to see the output of the testing data and comparing it to your output.\n",
    "- Initially the test case will be failed as there is no code in the below two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:24:33.428213Z",
     "start_time": "2020-09-10T01:24:33.423898Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bc7e76c2c1a5ce1942a310ff8c6ce8f",
     "grade": false,
     "grade_id": "normalization",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def normalization (fname, attr, normType):\n",
    "    '''\n",
    "    Input Parameters:\n",
    "        fname: Name of the csv file contiaining historical quotes\n",
    "        attr: The attribute to be normalized \n",
    "        normType: The type of normalization \n",
    "    Output:\n",
    "        a dictionary where each key is the original column value and each value is the normalised column value. \n",
    "    '''\n",
    "    result = {\n",
    "        \n",
    "    }\n",
    "    \n",
    "    d =  ['Open','High','Low','Close','Volume']\n",
    "    df = pd.read_csv(fname)\n",
    "    if type(attr) == type(1):\n",
    "        dff = df[df.columns[attr]]\n",
    "    else:\n",
    "        dff = df[attr]\n",
    "    \n",
    "    dff_min = dff.min()\n",
    "    dff_max = dff.max()\n",
    "    dff_std = dff.std()\n",
    "    dff_mean = dff.mean()\n",
    "    \n",
    "    def min_max(v):\n",
    "        return ((v - dff_min) / (dff_max - dff_min))\n",
    "\n",
    "    def z_score(v):\n",
    "        return ((v - dff_mean) / dff_std)\n",
    "        \n",
    "    for key in dff:\n",
    "        if normType == \"z_score\":\n",
    "            result[key] = z_score(key)\n",
    "        else:\n",
    "            result[key] = min_max(key)\n",
    "        \n",
    "        \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization(\"./data/normalization_test_data.csv\", 0, \"z_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization('./data/HistoricalQuotes.csv', 'Open', 'z_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization('./data/HistoricalQuotes.csv', 'Volume', 'z_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = correlation('./data/correlation_test_data.csv', 0, \"./data/correlation_test_data.csv\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = normalization(\"./data/normalization_test_data.csv\", 1, \"z_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e0d7d290878957d9535e285ed9ba393",
     "grade": true,
     "grade_id": "test_normalization",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell has hidden test cases that will run after you submit your assignment. \\nYou can troubleshoot using the unit tests we shared below.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell has hidden test cases that will run after you submit your assignment. \n",
    "You can troubleshoot using the unit tests we shared below.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:24:55.210777Z",
     "start_time": "2020-09-10T01:24:55.201476Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "862c679b0e1c220375a75868ae05a503",
     "grade": false,
     "grade_id": "correlation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def correlation (fname1, attr1, fname2, attr2):\n",
    "    '''\n",
    "    Input Parameters:\n",
    "        fname1: name of the first csv file containing historical quotes\n",
    "        attr1: The attribute to consider in the first csv file (fname1)\n",
    "        fname2: name of the second csv file containing historical quotes\n",
    "        attr2: The attribute to consider in the second csv file (fname2)\n",
    "        \n",
    "    Output:\n",
    "        correlation coefficient between attr1 in fname1 and attr2 in fname2\n",
    "    '''\n",
    "    \n",
    "    correlation_coefficient = 0.0\n",
    "        \n",
    "    df1 = pd.read_csv(fname1)\n",
    "    df2 = pd.read_csv(fname2)\n",
    "    dff1 = df1[df1.columns[attr1]]\n",
    "    dff2 = df2[df2.columns[attr2]]\n",
    "    correlation_coefficient = dff1.corr(dff2)\n",
    "    \n",
    "    \n",
    "    return correlation_coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ce = df1['Volume'].corr(df2['Open'])\n",
    "#ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f543a7eb3374de561e6640f3101fb49",
     "grade": true,
     "grade_id": "test_correlation",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell has hidden test cases that will run after you submit your assignment. \\nYou can troubleshoot using the unit tests we shared below.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell has hidden test cases that will run after you submit your assignment. \n",
    "You can troubleshoot using the unit tests we shared below.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:28:36.101216Z",
     "start_time": "2020-09-10T01:28:36.049564Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.029s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestKnn(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.loc1 = \"data/test1.csv\"\n",
    "        self.loc2 = \"data/test2.csv\"\n",
    "        file = open('data/testing_normalization', 'rb')\n",
    "        self.data_normalization = pickle.load(file)\n",
    "        file.close()\n",
    "        file = open('data/testing_correlation', 'rb')\n",
    "        self.data_correlation = pickle.load(file)\n",
    "        file.close()\n",
    "        file = open('data/testing_zscore', 'rb')\n",
    "        self.zscore = pickle.load(file)\n",
    "        \n",
    "    def test0(self):\n",
    "        \"\"\"\n",
    "        Test the label counter \n",
    "        \"\"\"\n",
    "        result = normalization(\"./data/normalization_test_data.csv\", 0, \"min_max\")\n",
    "        for key,value in self.data_normalization.items():\n",
    "            self.assertAlmostEqual(result[key],value, places = 1)\n",
    "            \n",
    "    \n",
    "    def test1(self):\n",
    "        \"\"\"\n",
    "           Test zcore normalization\n",
    "        \"\"\"\n",
    "        result = normalization(\"./data/normalization_test_data.csv\", 1, \"z_score\")\n",
    "        for key, value in self.zscore.items():\n",
    "            self.assertAlmostEqual(result[key], value, places = 1)\n",
    "    \n",
    "    def test2(self):\n",
    "        \"\"\"\n",
    "        Test the label counter \n",
    "        \"\"\"\n",
    "        result = correlation('./data/correlation_test_data.csv', 0, \"./data/correlation_test_data.csv\", 0)\n",
    "        self.assertAlmostEqual(result,self.data_correlation, places = 1)\n",
    "       \n",
    "   \n",
    "tests = TestKnn()\n",
    "tests_to_run = unittest.TestLoader().loadTestsFromModule(tests)\n",
    "unittest.TextTestRunner().run(tests_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "***\n",
    "\n",
    "There are 4 functions that need to be completed:\n",
    "\n",
    "1. For each of the graphs, the input function parameters and the expected output has been mentioned below.\n",
    "2. Use the dataset provided in \"./data/HistoricalQuotes.csv\" to plot the below graphs.\n",
    "3. Instructions have been provided within each function regarding which attributes to choose from.\n",
    "4. The dataset has the following attributes\n",
    "    - Date\n",
    "    - Close\n",
    "    - Volume\n",
    "    - Open\n",
    "    - High\n",
    "    - Low\n",
    "\n",
    "Note:\n",
    "- Make sure the dataset you are using is the one mentioned in the problem statement.\n",
    "- After defining your functions. Create another block to call these functions by passing the attributes mentioned in canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# Plot size to 14\" x 7\"\n",
    "matplotlib.rc('figure', figsize = (14, 7))\n",
    "# Font size to 14\n",
    "matplotlib.rc('font', size = 14)\n",
    "# Do not display top and right frame lines\n",
    "matplotlib.rc('axes.spines', top = False, right = False)\n",
    "# Remove grid lines\n",
    "matplotlib.rc('axes', grid = False)\n",
    "# Set backgound color to white\n",
    "matplotlib.rc('axes', facecolor = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e320e21e3a51c6fc38e1065a5fce7b8",
     "grade": false,
     "grade_id": "cell-f262493a60cd8007",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def temporal_graph():\n",
    "    '''Input : x_data and y_data are the lists containing the data points for x and y axis\n",
    "    xlabel and ylabel are the labels that should be given to the corresponding axes\n",
    "    title contains the title of the graph\n",
    "    \n",
    "    Output : \n",
    "    Plot the temporal change of attributes High and Low values\n",
    "    Return a temporal graph with attributes Date on x-axis and a tuple of High and Low on y-axis displayed\n",
    "    \n",
    "    x_data - a python list of Dates using \"Date\" attribute from the dataset\n",
    "    y_data - a tuple of the High and Low values respectively. 'High' and 'Low' should be stored as python lists.\n",
    "             Ex: y_data = (list(df['attr_1']), list(df['attr_2']))\n",
    "    xlabel, ylabel - A string value representing the axes labels\n",
    "    title - A string representing the title for the graph\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv('./data/HistoricalQuotes.csv')\n",
    "    \n",
    "    x_data = list(df['Date'])\n",
    "    y_data = (list(df['High']), list(df['Low']))\n",
    "    xlabel = 'Date'\n",
    "    ylabel = '(High, Low)'\n",
    "    title = 'Temporal Graph'\n",
    "    \n",
    "    \n",
    "    return x_data,y_data,xlabel,ylabel,title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09/08/2020</td>\n",
       "      <td>38.19</td>\n",
       "      <td>16117250</td>\n",
       "      <td>38.52</td>\n",
       "      <td>39.180</td>\n",
       "      <td>38.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09/04/2020</td>\n",
       "      <td>39.87</td>\n",
       "      <td>17824990</td>\n",
       "      <td>41.20</td>\n",
       "      <td>41.490</td>\n",
       "      <td>38.4301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/03/2020</td>\n",
       "      <td>41.63</td>\n",
       "      <td>18760840</td>\n",
       "      <td>42.74</td>\n",
       "      <td>43.000</td>\n",
       "      <td>40.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09/02/2020</td>\n",
       "      <td>43.67</td>\n",
       "      <td>26800040</td>\n",
       "      <td>41.52</td>\n",
       "      <td>44.090</td>\n",
       "      <td>41.3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/01/2020</td>\n",
       "      <td>41.15</td>\n",
       "      <td>10478790</td>\n",
       "      <td>40.61</td>\n",
       "      <td>41.245</td>\n",
       "      <td>40.1400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Close    Volume   Open    High      Low\n",
       "0  09/08/2020  38.19  16117250  38.52  39.180  38.1000\n",
       "1  09/04/2020  39.87  17824990  41.20  41.490  38.4301\n",
       "2  09/03/2020  41.63  18760840  42.74  43.000  40.9600\n",
       "3  09/02/2020  43.67  26800040  41.52  44.090  41.3600\n",
       "4  09/01/2020  41.15  10478790  40.61  41.245  40.1400"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/HistoricalQuotes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10b78e6a952ddec151b6ef22c38ec8db",
     "grade": true,
     "grade_id": "cell-a8a9dace8000b375",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell has hidden test cases that will run after you submit your assignment. \\nYou can troubleshoot by calling the function and checking return types.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell has hidden test cases that will run after you submit your assignment. \n",
    "You can troubleshoot by calling the function and checking return types.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef467c73f896a2883c3e1bc51d35c11f",
     "grade": false,
     "grade_id": "cell-51ff89ef927d6018",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def boxplot():\n",
    "    '''Input : x_data and y_data are the lists containing the data points for x and y axis\n",
    "    base_color and median_color can be used to set colors in the graph.\n",
    "    xlabel and ylabel are the labels that should be given to the corresponding axes\n",
    "    title contains the title of the graph.\n",
    "    \n",
    "    Output : A boxplot with Open and Close attributes on the x-axis displayed\n",
    "    \n",
    "    x_data - a tuple of Open and Close values respectively. Open and Close should be stored as a python list.\n",
    "             Ex: x_data = (list(df['attr_1']), list(df['attr_2']))\n",
    "    xlabel, ylabel - A string value representing the axes labels\n",
    "    title - A string representing the title for the graph\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv('./data/HistoricalQuotes.csv')\n",
    "        \n",
    "    x_data = (list(df['Open']), list(df['Close']))\n",
    "    xlabel = 'Open'\n",
    "    ylabel = 'Close'\n",
    "    tittle = 'Boxplot'\n",
    "    \n",
    "    \n",
    "    return x_data,xlabel,ylabel,title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdca2d2c76a46b748804df557feadf39",
     "grade": true,
     "grade_id": "cell-34f53d2a937e45f2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell has hidden test cases that will run after you submit your assignment. \\nYou can troubleshoot by calling the function and checking return types.\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell has hidden test cases that will run after you submit your assignment. \n",
    "You can troubleshoot by calling the function and checking return types.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ab525c41e6e239d86036fcebe088341",
     "grade": false,
     "grade_id": "cell-6e477222af744e1e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def histogram():\n",
    "    '''Input : data is the list containing the data points for histogram buckets\n",
    "    xlabel and ylabel are the labels that should be given to the corresponding axes\n",
    "    title contains the title of the graph\n",
    "    \n",
    "    Output : A histogram of the Volume attribute displayed\n",
    "    \n",
    "    data - A python list containing the data associated with the Volume attribute\n",
    "    x_label, y_label - A string representing the axes labels \n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv('./data/HistoricalQuotes.csv')\n",
    "\n",
    "    data = list(df['Volume'])\n",
    "    \n",
    "    x_label = 'X'\n",
    "    y_label = 'Y'\n",
    "    \n",
    "    return data, x_label, y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4c6c8e00948adc5769275f48e7bd2d3",
     "grade": true,
     "grade_id": "cell-9719ed64b0c27717",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell has hidden test cases that will run after you submit your assignment. \\nYou can troubleshoot by calling the function and checking return types.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell has hidden test cases that will run after you submit your assignment. \n",
    "You can troubleshoot by calling the function and checking return types.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amzn_new_plot():\n",
    "    '''Define this function as you would seem fit to display the plot that interests you using\n",
    "    the same dataset. Define your function parameters and display the resulting plots'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
