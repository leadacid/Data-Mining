{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e413b24cf2f4ff97ee541826571fb8f",
     "grade": false,
     "grade_id": "cell-4e1696969eb81f75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Homework 1 -  Frequent Pattern Analysis\n",
    "***\n",
    "**Name**: $<$insert name here$>$ \n",
    "***\n",
    "\n",
    "Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "859fb2ffd4d82989d0cbc1fa55ab8970",
     "grade": false,
     "grade_id": "cell-a0424d7dd292f236",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The rules to be followed for the assignment are:\n",
    "\n",
    "- Do **NOT** load additional packages beyond what we've shared in the cells below.\n",
    "- Some problems with code may be autograded.  If we provide a function or class API **do not** change it.\n",
    "- Do not change the location of the data or data directory.  Use only relative paths to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f0fc7cdd13720bf65f2713d85f14294",
     "grade": false,
     "grade_id": "cell-208e6b52f66e263b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "550feb4db919af7af5bd76039b77502b",
     "grade": false,
     "grade_id": "cell-41899a355c39fa18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [10 points] Problem 1 - Apriori Implementation\n",
    "***\n",
    "\n",
    "A sample dataset has been provided to you in the './data/dataset.pickle' path. Here are the attributes for the dataset. Use this dataset to test your functions.\n",
    "\n",
    "- Dataset should load the transactions in the form of a python dictionary where each key holds the transaction id and the value is a python list of the items purchased in that transaction. \n",
    "- An example transaction will have the following structure. If items A, C, D, F are purchased in transaction T3, this would appear as follows in the dictionary.\n",
    "\n",
    "```python\n",
    "transactions = {\n",
    "   \"T3\": [\"A\", \"C\", \"D\", \"F\"]\n",
    "}\n",
    "```\n",
    "\n",
    "Note:\n",
    "- A sample dataset to test your code has been provided in the location \"./data/dataset.pickle\". Please maintain this as it would be necessary while grading.\n",
    "- Do not change the variable names of the returned values.\n",
    "- After calculating each of those values, assign them to the corresponding value that is being returned.\n",
    "\n",
    "- If you are encountering any errors while loading the dataset, the following lines of code should help. Please delete the cells before submitting, to reduce any potential autograder issues.\n",
    "\n",
    "```python\n",
    "!pip install pickle5\n",
    "\n",
    "import pickle5 as pickle\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "  \n",
    "def findsubsets(s, n):\n",
    "    \n",
    "#   A helper function that you can use to list of all subsets of size n. Do not make any changes to this code block.\n",
    "#   Input: \n",
    "#       1. s - A python list of items\n",
    "#       2. n - Size of each subset\n",
    "#   Output:\n",
    "#       1. subsets - A python list containing the subsets of size n.\n",
    "    subsets = list(sorted((itertools.combinations(s,n))))\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_from_frequent_itemsets(frequent_itemset):\n",
    "\n",
    "#   A helper function that you can use to get the sorted items from the frequent itemsets. Do not make any changes\n",
    "#   to this code block\n",
    "#   Input:\n",
    "#       1. Frequent Itemsets\n",
    "#   Output:\n",
    "#       1. Sorted list of items\n",
    "\n",
    "    items = list()\n",
    "    for keys in frequent_itemset.keys():\n",
    "        for item in list(keys):\n",
    "            items.append(item)\n",
    "    return sorted(list(set(items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c6a9b607de9874a42fa55da4dea5ed1",
     "grade": false,
     "grade_id": "cell-8aeecaf8c900b493",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_frequent_itemsets(dataset, support, items, n=1, frequent_items={}):\n",
    "    \n",
    "#   Input:\n",
    "#       1. dataset - A python dictionary containing the transactions.\n",
    "#       2. support - A floating point variable representing the min_support value for the set of transactions.\n",
    "#       3. items - A python list representing all the items that are part of all the transactions.\n",
    "#       4. n - An integer variable representing what frequent item pairs to generate.\n",
    "#       5. frequent_items - A dictionary representing k-1 frequent sets. \n",
    "#   Output:\n",
    "#       1. frequent_itemsets - A dictionary representing the frequent itemsets and their corresponding support counts.\n",
    "    \n",
    "    len_transactions = len(dataset)\n",
    "    rip = len_transactions * support\n",
    "    fd = {}\n",
    "    frequent_itemsets = {}\n",
    "        \n",
    "    if n == 1:\n",
    "        for item in items:\n",
    "            fd[item] = 0\n",
    "            \n",
    "        for T in dataset.values():\n",
    "            for letter in T:\n",
    "                fd[letter] += 1\n",
    "    \n",
    "    else:\n",
    "        for item in findsubsets(items,n):\n",
    "            fd[item] = 0\n",
    "        for T in dataset.values():\n",
    "            ss = findsubsets(T, n)\n",
    "            for val in ss:\n",
    "                fd[val] += 1\n",
    "    for key in fd:\n",
    "        if fd[key] >= rip:\n",
    "             frequent_itemsets[key] = fd[key]\n",
    "    return frequent_itemsets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pickle5\n",
    "#import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8eab04a351ad1812a95cd02b5e4a19b",
     "grade": true,
     "grade_id": "cell-9189aa11b7c2f094",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: frequent 1 itemsets\n",
      "{('A', 'B'): 3, ('B', 'D'): 4}\n",
      "Test 2: frequent 2 itemsets\n",
      "{}\n",
      "Test 3: frequent 3 itemsets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestX(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.min_support = 0.5\n",
    "        self.items = ['A', 'B', 'C', 'D', 'E']\n",
    "        self.dataset = dict()\n",
    "        self.dataset[\"T1\"] = ['A', 'B', 'D']\n",
    "        self.dataset[\"T2\"] = ['A', 'B', 'E']\n",
    "        self.dataset[\"T3\"] = ['B', 'C', 'D']\n",
    "        self.dataset[\"T4\"] = ['B', 'D', 'E']        \n",
    "        self.dataset[\"T5\"] = ['A', 'B', 'C', 'D']\n",
    "        \n",
    "    def test0(self):\n",
    "        frequent_1_itemsets = generate_frequent_itemsets(self.dataset, self.min_support, self.items)\n",
    "        frequent_1_itemsets_solution = dict()\n",
    "        frequent_1_itemsets_solution['A'] = 3\n",
    "        frequent_1_itemsets_solution['B'] = 5\n",
    "        frequent_1_itemsets_solution['D'] = 4\n",
    "\n",
    "        print (\"Test 1: frequent 1 itemsets\")\n",
    "        #print(frequent_1_itemsets_solution)\n",
    "        assert frequent_1_itemsets == frequent_1_itemsets_solution\n",
    "\n",
    "        frequent_2_itemsets = generate_frequent_itemsets(self.dataset, self.min_support, self.items, 2, frequent_1_itemsets)\n",
    "        print (frequent_2_itemsets)\n",
    "        frequent_2_itemsets_solution = dict()\n",
    "        frequent_2_itemsets_solution[('A', 'B')] = 3\n",
    "        frequent_2_itemsets_solution[('B', 'D')] = 4\n",
    "        \n",
    "        print (\"Test 2: frequent 2 itemsets\")\n",
    "        #print(frequent_2_itemsets_solution)\n",
    "        assert frequent_2_itemsets == frequent_2_itemsets_solution\n",
    "\n",
    "        frequent_3_itemsets = generate_frequent_itemsets(self.dataset, self.min_support, self.items, 3, frequent_2_itemsets)\n",
    "        print (frequent_3_itemsets)\n",
    "        frequent_3_itemsets_solution = dict()\n",
    "\n",
    "        print (\"Test 3: frequent 3 itemsets\")\n",
    "        #print(frequent_3_itemsets == frequent_3_itemsets_solution)\n",
    "        assert frequent_3_itemsets == frequent_3_itemsets_solution         \n",
    "   \n",
    "tests = TestX()\n",
    "tests_to_run = unittest.TestLoader().loadTestsFromModule(tests)\n",
    "unittest.TextTestRunner().run(tests_to_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 6, 'B': 6, 'C': 7, 'D': 9, 'E': 5}\n"
     ]
    }
   ],
   "source": [
    "with open('./data/dataset.pickle', 'rb') as f:\n",
    "\tdata = pickle.load(f)\n",
    "items = ['A', 'B', 'C', 'D', 'E']\n",
    "min_support = 0.5\n",
    "frequent_1_itemsets = generate_frequent_itemsets(data, min_support, items)\n",
    "print(frequent_1_itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10 points] Problem 2 - FP-Growth Implementation\n",
    "***\n",
    "\n",
    "A sample dataset has been provided to you in the './data/dataset.pickle' path. Here are the attributes for the dataset. Use this dataset to test your functions.\n",
    "\n",
    "- Dataset should load the transactions in the form of a python dictionary where each key holds the transaction id and the value is a python list of the items purchased in that transaction. \n",
    "- An example transaction will have the following structure. If items A, C, D, F are purchased in transaction T3, this would appear as follows in the dictionary.\n",
    "\n",
    "```python\n",
    "transactions = {\n",
    "   \"T3\": [\"A\", \"C\", \"D\", \"F\"]\n",
    "}\n",
    "```\n",
    "\n",
    "Note:\n",
    "- A sample dataset to test your code has been provided in the location \"./data/dataset.pickle\". Please maintain this as it would be necessary while grading.\n",
    "- Do not change the variable names of the returned values.\n",
    "- After calculating each of those values, assign them to the corresponding value that is being returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "203c4e5353d0b261f7d8eec326a15bd0",
     "grade": false,
     "grade_id": "cell-044bd5cae7c41526",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def item_support(dataset, min_support):\n",
    "    \n",
    "#   A helper function that returns the support count of each item in the dataset.\n",
    "#   Input:\n",
    "#       1. dataset - A python dictionary containing the transactions. \n",
    "#       2. min_support - A floating point variable representing the min_support value for the set of transactions.\n",
    "#   Output:\n",
    "#       1. support_dict - A dictionary representing the support count of each item in the dataset.\n",
    "    \n",
    "    len_transactions = len(dataset)\n",
    "    support_dict = dict()\n",
    "    temp = {}\n",
    "    for key, value in dataset.items():\n",
    "        for val in value:\n",
    "            try:\n",
    "                temp[val] += 1\n",
    "            except:\n",
    "                temp[val] = 1\n",
    "    \n",
    "    rip = len_transactions * min_support\n",
    "    for key in temp:\n",
    "        if temp[key] >= rip:\n",
    "            support_dict[key] = temp[key]\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    ### For reference only\n",
    "    sorted_support = dict(sorted(support_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    pruned_support = {key:val for key, val in sorted_support.items() if val/len_transactions >= min_support}\n",
    "    ###\n",
    "    \n",
    "    return support_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 7, 'D': 9, 'E': 5, 'B': 6, 'A': 6}\n"
     ]
    }
   ],
   "source": [
    "frequent_2_itemsets = item_support(data, min_support)\n",
    "print(frequent_2_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01c2205b421f343b2900235853035d64",
     "grade": true,
     "grade_id": "cell-330eca95a174c213",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9faf8566119f9053cd938aa7a601245",
     "grade": false,
     "grade_id": "cell-94f1180e7b0df5fe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def reorder_transactions(dataset, min_support):\n",
    "    \n",
    "#   A helper function that reorders the transaction items based on maximum support count. It is important that you finish\n",
    "#   the code in the previous cells since this function makes use of the support count dictionary calculated above.\n",
    "#   Input:\n",
    "#       1. dataset - A python dictionary containing the transactions. \n",
    "#       2. min_support - A floating point variable representing the min_support value for the set of transactions.\n",
    "#   Output:\n",
    "#       1. updated_dataset - A dictionary representing the transaction items in sorted order of their support counts.\n",
    "\n",
    "    pruned_support = item_support(dataset, min_support) \n",
    "    updated_dataset = dict()\n",
    "    \n",
    "    # This loop sorts the transaction items based on the item support counts\n",
    "    for key, value in dataset.items():\n",
    "        updated_dataset[key] = sorted(value, key=pruned_support.get, reverse=True)\n",
    "\n",
    "    \n",
    "    # Update the following loop to remove items that do not belong to the pruned_support dictionary\n",
    "    for key, value in updated_dataset.items():\n",
    "        updated_values = list()\n",
    "        for item in value:\n",
    "            if item in pruned_support:\n",
    "                updated_values.append(item)\n",
    "            \n",
    "        updated_dataset[key] = updated_values\n",
    "\n",
    "    return updated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 ['D', 'C', 'E']\n",
      "T2 ['D', 'C', 'B']\n",
      "T3 ['D', 'C', 'A']\n",
      "T4 ['D', 'C', 'A', 'E']\n",
      "T5 ['D', 'C', 'A', 'B']\n",
      "T6 ['B']\n",
      "T7 ['D', 'E']\n",
      "T8 ['D', 'C', 'A', 'B']\n",
      "T9 ['D', 'A', 'B', 'E']\n",
      "T10 ['D', 'C', 'A', 'B', 'E']\n"
     ]
    }
   ],
   "source": [
    "frequent_3_itemsets = reorder_transactions(data, min_support)\n",
    "for i,y in frequent_3_itemsets.items():\n",
    "    print(i,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b17bc50d8a8f867ddb8b3d2aef80fee",
     "grade": true,
     "grade_id": "cell-f75886c98dbd692b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bcd039f72cfadd9a9875f3bf12015b66",
     "grade": false,
     "grade_id": "cell-d8903df190fbb499",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def build_fp_tree(updated_dataset):\n",
    "    \n",
    "#   Input: \n",
    "#       1. updated_dataset - A python dictionary containing the updated set of transactions based on the pruned support dictionary.\n",
    "#   Output:\n",
    "#       1. fp_tree - A dictionary representing the fp_tree. Each node should have a count and children attribute.\n",
    "#        \n",
    "#   HINT:\n",
    "#       1. Loop over each transaction in the dataset and make an update to the fp_tree dictionary. \n",
    "#       2. For each loop iteration store a pointer to the previously visited node and update it's children in the next pass.\n",
    "#       3. Update the root pointer when you start processing items in each transaction.\n",
    "#       4. Reset the root pointer for each transaction.\n",
    "#\n",
    "#   Sample Tree Output:\n",
    "#   {'Y': {'count': 3, 'children': {'V': {'count': 1, 'children': {}}}},\n",
    "#    'X': {'count': 2, 'children': {'R': {'count': 1, 'children': {'F': {'count': 1, 'children': {}}}}}}}\n",
    "    \n",
    "    fp_tree = dict()\n",
    "    \n",
    "    b = 'children'\n",
    "    a = 'count'\n",
    "    for key, value in updated_dataset.items():\n",
    "        for p in range(len(value)):\n",
    "            if p == 0:\n",
    "                try:\n",
    "                    fp_tree[value[0]][a] += 1\n",
    "                except:\n",
    "                    fp_tree[value[0]] = {a:1, b: {}}\n",
    "            \n",
    "            if p == 1:\n",
    "                try:\n",
    "                    fp_tree[value[0]][b][value[1]][a] += 1\n",
    "                except:\n",
    "                    fp_tree[value[0]][b][value[1]] = {a:1, b: {}}\n",
    "            if p == 2:\n",
    "                try:\n",
    "                    fp_tree[value[0]][b][value[1]][b][value[2]][a] += 1\n",
    "                except:\n",
    "                    fp_tree[value[0]][b][value[1]][b][value[2]] = {a:1, b: {}}\n",
    "            if p == 3:\n",
    "                try:\n",
    "                    fp_tree[value[0]][b][value[1]][b][value[2]][b][value[3]][a] += 1\n",
    "                except:\n",
    "                    fp_tree[value[0]][b][value[1]][b][value[2]][b][value[3]] = {a:1, b: {}}\n",
    "            if p == 4:\n",
    "                try:\n",
    "                    fp_tree[value[0]][b][value[1]][b][value[2]][b][value[3]][b][value[4]][a] += 1\n",
    "                except:\n",
    "                    fp_tree[value[0]][b][value[1]][b][value[2]][b][value[3]][b][value[4]] = {a:1, b: {}}\n",
    "                        \n",
    "        \n",
    "       \n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "    return fp_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3487da265f4be3ad38b04e0a905b7da4",
     "grade": true,
     "grade_id": "cell-2e8a2c6ab7c275e5",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D': {'count': 9, 'children': {'C': {'count': 7, 'children': {'E': {'count': 1, 'children': {}}, 'B': {'count': 1, 'children': {}}, 'A': {'count': 5, 'children': {'E': {'count': 1, 'children': {}}, 'B': {'count': 3, 'children': {'E': {'count': 1, 'children': {}}}}}}}}, 'E': {'count': 1, 'children': {}}, 'A': {'count': 1, 'children': {'B': {'count': 1, 'children': {'E': {'count': 1, 'children': {}}}}}}}}, 'B': {'count': 1, 'children': {}}}\n"
     ]
    }
   ],
   "source": [
    "frequent_4_itemsets = build_fp_tree(frequent_3_itemsets)\n",
    "print(frequent_4_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D': {'count': 9, 'children': {'C': {'count': 7, 'children': {'E': {'count': 1, 'children': {}}, 'B': {'count': 1, 'children': {}}, 'A': {'count': 5, 'children': {'E': {'count': 1, 'children': {}}, 'B': {'count': 3, 'children': {'E': {'count': 1, 'children': {}}}}}}}}, 'E': {'count': 1, 'children': {}}, 'A': {'count': 1, 'children': {'B': {'count': 1, 'children': {'E': {'count': 1, 'children': {}}}}}}}}, 'B': {'count': 1, 'children': {}}}\n"
     ]
    }
   ],
   "source": [
    "frequent_4_itemsets = build_fp_tree(frequent_3_itemsets)\n",
    "print(frequent_4_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': 9, 'C': 7, 'E': 5, 'B': 6, 'A': 6}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_support(frequent_3_itemsets,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
